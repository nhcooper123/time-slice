---
title: "Time slice analyses"
author: "Natalie Cooper and Thomas Guillerme"
date: "`r Sys.Date()`"
output:
  html_document:
    fig_width: 6
    fig_height: 6
---

This code runs the analyses in the paper. Below we lay out the process in detail for one dataset, and then provide the code for the other datasets below this. Note that much of this uses functions in the `simulations.R` file.

```{r}
set.seed(123)
```

Load packages and functions
-----------------------------------

Make sure you work with `dispRity` 0.4 and TG's version of `Claddis` (much faster than GL's).

```{r, eval = TRUE, message = FALSE}
# The latest version of devtools and ape
library(devtools)
library(ape)

## The latest version of Claddis (on development on TG branch)
## install_github("TGuillerme/Claddis")
library(Claddis)

## The latest version of dispRity on master branch
## install_github("TGuillerme/dispRity", ref = "master")
library(dispRity) 

## Load functions using source
# Doesn't always work... Rmd problem?
source("../functions/simulations_fun.R")
```

Loading the data
-----------------------------------

To run `dispRity` analyses we need the **morphospace**, the **phylogeny** (with a root age and node labels) and the **first and last occurrence dates** (FADLAD). The tree and FADLAD are in the `data/` folder. To construct the morphospace we need to use the `distance_matrix` files we created in `01-extract-data-for analyses.Rmd` and stored in `data/processed`.

```{r}
## Choose a slug
slug <- "Beck2014"

## Loading the discrete morphological matrix
## This is just to match the names with the tree
matrix <- ReadMorphNexus(paste0("../data/matrices/", slug, ".nex"))

## Loading the FADLAD
FADLAD <- read.csv(paste0("../data/FADLAD/", slug, ".csv"), row.names = 1, header = TRUE)

## Loading the tree
tree <- read.nexus(paste0("../data/trees/", slug, ".tre"))
## Adding node labels and a root age (max tree age date)
tree <- makeNodeLabel(tree, method = "number", prefix = "n")
tree$root.time <- max(tree.age(tree)[, 1])

## Cleaning the tree to remove things that aren't in the matrix 
cleaned_data <- clean.data(matrix$matrix, tree)
matrix$matrix <- cleaned_data$matrix
tree <- cleaned_data$tree

## Loading the distance matrices
## See "01-extract-data-for analyses.Rmd" for how we made these
load(paste0("../data/processed/distance_matrix.", slug ,".Rda"))

## Ordinating the matrix
morphospace <- cmdscale(matrix_dist, k = nrow(matrix_dist) - 2, add = TRUE)$points

```

Scenarios
--------------------------------

We used the data to explore these different scenarios:

1. Stratigraphy. This is the traditional method, where all the species within each stratigraphic period are included in the disparity calculation. This often leads to bins of unequal duration.

2. Equally sized time bins. 
    i. Where the *duration* of the bin is equal to the median duration of the stratigraphic period.
    ii. Where the *number* of bins is equal to the number of stratigraphic periods.
    iii. Where the *number* of bins is either 2, 5, 10, 15, or 20.

3. Time slicing. 
    i. Where the *interval* between slices is equal to the median duration of the stratigraphic period.
    ii. Where the *number* of slices is equal to the number of stratigraphic periods.
    iii. Where the *number* of slices is either 2, 5, 10, 15, or 20.

Running the analyses and saving the outputs
--------------------------------------------

These analyses use a series of functions in `functions\`. These essentially wrap the existing `dispRity` functions so that running lots of models and extracting lots of data is not such a big issue.

```{r, eval = FALSE, warning = FALSE}
## Run the function for Beck data
slug <- "BeckLee"

## Ages
out1 <- run.all.disparity.strat(morphospace, tree, type = "Age", FADLAD, inc.nodes = TRUE,
                                bootstraps = 100, metric = c(sum, variances), metric.name = "sum_var")
readr::write_csv(out1, path = paste0("../outputs/age", "_", slug, ".csv"))

## Epochs
out2 <- run.all.disparity.strat(morphospace, tree, type = "Epoch", FADLAD, inc.nodes = TRUE,
                        bootstraps = 100, metric = c(sum, variances), metric.name = "sum_var")
readr::write_csv(out2, path = paste0("../outputs/epoch", "_", slug, ".csv"))
```

<!-- Both the above throw this error:

Error in if (is.na(data$subsamples[subsamples_check[subsample]][[1]]$elements[1, : argument is of length zero -->

We also ran the models using varying numbers of bins as follows.

```{r, eval = FALSE}
## Run the function for Beck data
slug <- "BeckLee"

for (bins in c(2, 5, 10, 15, 20)){
  output <- run.all.disparity(morphospace, tree, bins, FADLAD, inc.nodes = TRUE,
                              bootstraps = 100, metric = c(sum, variances), metric.name = "sum_var")
  
  readr::write_csv(output, path = paste0("../outputs/bins", "_", slug, ".csv"), append = TRUE)
}

```
<!-- Need to think more about the outputs here, currently they don't make much sense as there are no column headers -->



<!-- TG: Suggestion for a "testing the effect of binning/slicing" pipeline -->

Examining the output 
--------------------

Plots
Statistics
